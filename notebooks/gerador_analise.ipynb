{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, skewnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRLINE_COUNT=3\n",
    "DAILY_FLIGHT_COUNT=15\n",
    "DAILY_FLIGHT_OPTIONS = 30\n",
    "ORIGIN_COUNT=10\n",
    "AIRCRAFT_TYPES = ['Boeing 737', 'Airbus A320', 'Boeing 777', 'Airbus A330', 'Boeing 787', 'Embraer E175']\n",
    "HOLIDAY_COUNT = 20\n",
    "YEAR_FROM=2010\n",
    "YEAR_TO=2022\n",
    "SEED = 41\n",
    "AIRCRAFT_WEIGHTS_DELAY = {'Boeing 737':15, 'Airbus A320':10, 'Boeing 777':5, 'Airbus A330':-5, 'Boeing 787':-5, 'Embraer E175':-10}\n",
    "AIRCRAFT_WEIGHTS_VAR_DELAY = {'Boeing 737':5, 'Airbus A320':4, 'Boeing 777':2, 'Airbus A330':1, 'Boeing 787':1, 'Embraer E175':4}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "#random.seed(SEED)\n",
    "\n",
    "def mixture_rvs(size, w1, mu1, var1, mu2, var2):\n",
    "    w2 = 1 - w1\n",
    "    # Draw uniform random numbers to decide which distribution to sample from\n",
    "    mixture_component = np.random.choice([0, 1], p=[w1, w2], size=size)\n",
    "\n",
    "    # Sample from the appropriate normal distribution for each component\n",
    "    samples = np.where(\n",
    "        mixture_component == 0,\n",
    "        norm.rvs(loc=mu1, scale=np.sqrt(var1), size=size),\n",
    "        norm.rvs(loc=mu2, scale=np.sqrt(var2), size=size)\n",
    "    )\n",
    "\n",
    "    return samples\n",
    "\n",
    "class Airline:\n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        self.seeds = [random.random() for i in range(6)]\n",
    "        # delay center between -30 and 30\n",
    "        self.delay_center = random.randint(-20, 35)\n",
    "        self.delay_var = random.randint(0,40)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.code\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.code\n",
    "\n",
    "def generate_origin(current):\n",
    "    while True:\n",
    "        # creates a random tree letter origin code\n",
    "        origin = []\n",
    "        origin.append(chr(random.randint(65, 90)))\n",
    "        origin.append(chr(random.randint(65, 90)))\n",
    "        origin.append(chr(random.randint(65, 90)))\n",
    "        origin = ''.join(origin)\n",
    "        # checks if the origin code is already in use\n",
    "        if origin not in current:\n",
    "            return origin\n",
    "\n",
    "def generate_flight(airlines, k, origins):\n",
    "    flight = []\n",
    "\n",
    "    # flight k\n",
    "    flight.append(k)\n",
    "\n",
    "    # flight id (LL3050)\n",
    "    airline = random.choices(airlines, weights=[7,2,1])[0]\n",
    "    flight.append(airline)\n",
    "\n",
    "    # weighted for aircraft type\n",
    "    aircraft_type = random.choices(AIRCRAFT_TYPES, weights=[\n",
    "            10 * airline.seeds[0],\n",
    "            10 * airline.seeds[1],\n",
    "            6 * airline.seeds[2],\n",
    "            5 * airline.seeds[3],\n",
    "            5 * airline.seeds[4],\n",
    "            4 * airline.seeds[5]])[0]\n",
    "    flight.append(aircraft_type)\n",
    "\n",
    "    # 80% is schengen\n",
    "    flight.append(random.choices(['schengen', 'non-schengen'], weights=[8, 2])[0])\n",
    "\n",
    "    # random origin\n",
    "    flight.append(random.choices(origins, weights=[\n",
    "            random.randint(1,10) * airline.seeds[0],\n",
    "            random.randint(1,10) * airline.seeds[1],\n",
    "            random.randint(1,10) * airline.seeds[2],\n",
    "            random.randint(1,10) * airline.seeds[3],\n",
    "            random.randint(1,10) * airline.seeds[4],\n",
    "            random.randint(1,10) * airline.seeds[5],\n",
    "            random.randint(1,10) * airline.seeds[2],\n",
    "            random.randint(1,10) * airline.seeds[3],\n",
    "            random.randint(1,10) * airline.seeds[4],\n",
    "            random.randint(1,10) * airline.seeds[5]])[0])\n",
    "\n",
    "    # arrival time\n",
    "    # using a normal distribution centered at 9:00 and another centered at 17 with a standard deviation of 2 hours\n",
    "    # create a normal centered on 9, var 2\n",
    "    arrival_time = mixture_rvs(1, 0.5, 9, 2, 17, 2)[0]\n",
    "    flight.append(arrival_time)\n",
    "\n",
    "    # staying time is normal mu=3, var=1, minimum should be 1h\n",
    "    staying_time = max(2, int(norm.rvs(loc=3.5, scale=1, size=1)[0]))\n",
    "    departure_time = arrival_time + staying_time\n",
    "    flight.append(departure_time)\n",
    "\n",
    "    return flight\n",
    "\n",
    "def generate_airline(current):\n",
    "    while True:\n",
    "        # creates a random two letter airline code\n",
    "        airline = []\n",
    "        airline.append(chr(random.randint(65, 90)))\n",
    "        airline.append(chr(random.randint(65, 90)))\n",
    "        airline = ''.join(airline)\n",
    "        # checks if the airline code is already in use\n",
    "        if airline not in current:\n",
    "            return Airline(airline)\n",
    "\n",
    "def generate_holiday(current):\n",
    "    while True:\n",
    "        # picks a random number between 1 and 365\n",
    "        holiday = random.randint(1, 365)\n",
    "        # checks if the holiday is already in use\n",
    "        if holiday not in current:\n",
    "            return holiday\n",
    "\n",
    "def generate_real_flight(base_flight, year, day, holidays, origins_weights, origins_weights_var, noise_list):\n",
    "    flight = []\n",
    "    flight.extend(base_flight)\n",
    "\n",
    "    delay_center = base_flight[1].delay_center\n",
    "    delay_var = base_flight[1].delay_var\n",
    "    # delay is normal on the center with 15 var\n",
    "    delay = skewnorm.rvs(a = 6, loc=delay_center, scale=delay_var, size=1)[0]\n",
    "\n",
    "    # in holiday delay center is worse in plus between 10 and 60\n",
    "    is_holiday = day in holidays\n",
    "    if is_holiday:\n",
    "        # use a normal\n",
    "        delay += skewnorm.rvs(a = 4, loc=25, scale=8, size=1)[0]\n",
    "\n",
    "    # in weekend delay center is worse in plus between 10 and 30\n",
    "    is_weekend = day % 7 == 0 or day % 7 == 6\n",
    "    if is_weekend:\n",
    "        # use a normal\n",
    "        delay += skewnorm.rvs(a = 4, loc=15, scale=10, size=1)[0]\n",
    "\n",
    "    delay += norm.rvs(loc=AIRCRAFT_WEIGHTS_DELAY[base_flight[2]], scale=AIRCRAFT_WEIGHTS_VAR_DELAY[base_flight[2]], size=1)[0]\n",
    "\n",
    "    delay += norm.rvs(loc=origins_weights[base_flight[4]], scale=origins_weights_var[base_flight[4]], size=1)[0]\n",
    "\n",
    "    # # in some airlines delay center is worse in plus between 10 and 30\n",
    "    # is_worse_airline = base_flight[1].code in worse_airlines\n",
    "    # if is_worse_airline:\n",
    "    #     # use a normal\n",
    "    #     delay += norm.rvs(loc=20, scale=5, size=1)[0]\n",
    "\n",
    "    r = random.random()\n",
    "    if r> 0.995:\n",
    "        noise = random.random() * 60\n",
    "    elif r > 0.9:\n",
    "        noise = random.random() * 30\n",
    "    elif r > 0.8:\n",
    "        noise = random.random() * 10\n",
    "    elif r > 0.6:\n",
    "        noise = random.random() * 5\n",
    "    else:\n",
    "        noise = random.random() - 0.5\n",
    "\n",
    "    #save the noise on a list\n",
    "    noise_list.append(noise)\n",
    "\n",
    "            \n",
    "    delay += noise\n",
    "\n",
    "    flight.append(day)\n",
    "    flight.append(year)\n",
    "    flight.append(is_holiday)\n",
    "    flight.append(delay)\n",
    "\n",
    "    return flight\n",
    "\n",
    "#funcition check the last file name and create a new one\n",
    "def check_file_name():\n",
    "    files = os.listdir('../data/data_study')\n",
    "    files = [file for file in files if file.startswith('flights_with_noise')]\n",
    "    if len(files) == 0:\n",
    "        return 'flights_with_noise_1.csv'\n",
    "    else:\n",
    "        files.sort()\n",
    "        last_file = files[-1]\n",
    "        number = int(last_file.split('_')[3].split('.')[0])\n",
    "        return f'flights_with_noise_{number+1}.csv'\n",
    "\n",
    "#function thats saves flights on a csv file\n",
    "def save_flights(flights, noise_list):\n",
    "\n",
    "    file_name = check_file_name()\n",
    "\n",
    "    with open(f'../data/data_study/{file_name}', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"flight_id\", \"airline\", \"aircraft_type\", \"schengen\", \"origin\", \"arrival_time\", \"departure_time\", \"day\", \"year\", \"is_holiday\", \"delay\"])\n",
    "        for flight in flights:\n",
    "            writer.writerow(flight)\n",
    "\n",
    "    #save the noise on a csv file name similiar as the flights file\n",
    "    with open(f'../data/data_study/noise_{file_name}', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"noise\"])\n",
    "        for noise in noise_list:\n",
    "            writer.writerow([noise])\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    noise_list = []\n",
    "    airlines = []\n",
    "\n",
    "    for i in range(AIRLINE_COUNT):\n",
    "        airlines.append(generate_airline(airlines))\n",
    "\n",
    "    # airlines with worse delays\n",
    "    # worse_airlines = [airline.code for airline in random.choices(airlines, k=5)]\n",
    "\n",
    "    origins = []\n",
    "    for i in range(ORIGIN_COUNT):\n",
    "        origins.append(generate_origin(origins))\n",
    "\n",
    "    origins_weights = {origem:random.randint(-15,15) for origem in origins}\n",
    "    origins_weights_var = {origem:random.randint(0,6) for origem in origins}\n",
    "\n",
    "    #dentro da função generate_holiday, verificar se o if já não garante a condição de não repetição então não precisa ser set pode ser list\n",
    "    holidays = set()\n",
    "    for i in range(HOLIDAY_COUNT):\n",
    "        h = generate_holiday(holidays)\n",
    "        holidays.add(h)\n",
    "\n",
    "    daily_flights_options = []\n",
    "    for i in range(1, DAILY_FLIGHT_OPTIONS + 1):\n",
    "        daily_flights_options.append(generate_flight(airlines, i, origins))\n",
    "\n",
    "    flights = []\n",
    "    for year in range(YEAR_FROM, YEAR_TO+1):\n",
    "        # TODO voos de dias especificos\n",
    "        # voos de natal\n",
    "        for day in range(365):\n",
    "            daily_flights = random.choices(daily_flights_options, k = DAILY_FLIGHT_COUNT)\n",
    "            for base_flight in daily_flights:\n",
    "                flights.append(generate_real_flight(base_flight, year, day, holidays, origins_weights, origins_weights_var, noise_list))\n",
    "    \n",
    "    save_flights(flights, noise_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv files and save on a list of Pandas DataFrames\n",
    "def read_csv_files():\n",
    "    files = os.listdir('../data/data_study')\n",
    "    files = [file for file in files if file.startswith('flights')]\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(f'../data/data_study/{file}'))\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of delay of file 1: 12.548378015698628\n",
      "mean of delay of file 2: 17.071611010697268\n",
      "mean of delay of file 3: 62.470021028987695\n",
      "mean of delay of file 4: 54.301755444776866\n",
      "mean of delay of file 5: 66.55132129549682\n",
      "mean of delay of file 6: 23.28533704475026\n",
      "mean of delay of file 7: 48.99147281973866\n",
      "mean of delay of file 8: 43.36273800655481\n",
      "mean of delay of file 9: 28.295264361113382\n"
     ]
    }
   ],
   "source": [
    "dfs = read_csv_files()\n",
    "\n",
    "#print the mean of delay of each file\n",
    "for i in range(len(dfs)):\n",
    "    print(f\"mean of delay of file {i+1}: {dfs[i]['delay'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of noise of file 0: 2.555992282326937\n",
      "mean of noise of file 1: 2.589714848528952\n",
      "mean of noise of file 2: 2.614312254509292\n",
      "mean of noise of file 3: 2.5805435377098584\n",
      "mean of noise of file 4: 2.5886580713841645\n",
      "mean of noise of file 5: 2.571388204108151\n",
      "mean of noise of file 6: 2.588789049362976\n"
     ]
    }
   ],
   "source": [
    "#read the noise csv file and save on a list of Pandas DataFrames\n",
    "def read_noise_files():\n",
    "    files = os.listdir('../data/data_study')\n",
    "    files = [file for file in files if file.startswith('noise')]\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(f'../data/data_study/{file}'))\n",
    "    return dfs\n",
    "\n",
    "noise_dfs = read_noise_files()\n",
    "\n",
    "#print the mean noise of each file\n",
    "for i in range(len(noise_dfs)):\n",
    "    print(f\"mean of noise of file {i}: {noise_dfs[i]['noise'].mean()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the only metric csv file and save on a DataFrames if exists else create a empty DataFrame\n",
    "def read_metrics_file():\n",
    "    files = os.listdir('../data/')\n",
    "    files = [file for file in files if file.startswith('metrics')]\n",
    "    if len(files) == 0:\n",
    "        return pd.DataFrame(columns=['file'])\n",
    "    else:\n",
    "        return pd.read_csv(f'../data/{files[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = read_metrics_file()\n",
    "\n",
    "for ind, dados in enumerate(dfs):\n",
    "\n",
    "    #only run if the file is not on the metrics file\n",
    "    if ind not in df_metrics['file'].values:\n",
    "\n",
    "        categorical_vars = ['airline', 'aircraft_type', 'origin']\n",
    "\n",
    "        # Perform one-hot encoding\n",
    "        df_encoded_4 = pd.get_dummies(dados, columns=categorical_vars, dtype=int)\n",
    "\n",
    "        df_encoded_4['is_holiday'] = df_encoded_4['is_holiday'].map({False: 0, True: 1})\n",
    "        df_encoded_4['schengen'] = df_encoded_4['schengen'].map({'non-schengen': 0, 'schengen': 1})\n",
    "        df_encoded_4['is_weekend'] = df_encoded_4['day'].apply(lambda day: day % 7 == 0 or day % 7 == 6)\n",
    "\n",
    "        X = df_encoded_4.drop(['flight_id', 'day', 'year','departure_time', 'delay'], axis=1)\n",
    "        y = df_encoded_4['delay']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # random_state=42\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "        rfe = RFE(model)\n",
    "        pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        #concat the metrics mae, mse, rmse, s2 of each file on a dataframe and the noise mean\n",
    "        # the first put none on noise column because the first file doesn't have noise\n",
    "        try:\n",
    "            noise = noise_dfs[ind-1]['noise'].mean()\n",
    "        except:\n",
    "            noise = None\n",
    "        \n",
    "        df_metrics = pd.concat([df_metrics, pd.DataFrame({'file': ind, 'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2, 'noise_mean': noise}, index=[ind])])\n",
    "\n",
    "#add the delay metrics, max, min, mean, mediam and std on the dataframe\n",
    "df_metrics['delay_median'] = df_metrics['file'].apply(lambda file: dfs[file]['delay'].median())\n",
    "df_metrics['delay_mean'] = df_metrics['file'].apply(lambda file: dfs[file]['delay'].mean())\n",
    "df_metrics['delay_std'] = df_metrics['file'].apply(lambda file: dfs[file]['delay'].std())\n",
    "df_metrics['delay_min'] = df_metrics['file'].apply(lambda file: dfs[file]['delay'].min())\n",
    "df_metrics['delay_max'] = df_metrics['file'].apply(lambda file: dfs[file]['delay'].max())\n",
    "\n",
    "#save the metrics on a csv file\n",
    "df_metrics.to_csv('../data/metrics.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>noise_mean</th>\n",
       "      <th>delay_median</th>\n",
       "      <th>delay_mean</th>\n",
       "      <th>delay_std</th>\n",
       "      <th>delay_min</th>\n",
       "      <th>delay_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7.935302</td>\n",
       "      <td>108.246762</td>\n",
       "      <td>10.404170</td>\n",
       "      <td>0.880453</td>\n",
       "      <td>2.571388</td>\n",
       "      <td>47.767941</td>\n",
       "      <td>48.991473</td>\n",
       "      <td>24.054547</td>\n",
       "      <td>-34.903859</td>\n",
       "      <td>225.296308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.935309</td>\n",
       "      <td>108.258770</td>\n",
       "      <td>10.404747</td>\n",
       "      <td>0.880439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.772060</td>\n",
       "      <td>43.362738</td>\n",
       "      <td>30.139726</td>\n",
       "      <td>-38.267560</td>\n",
       "      <td>170.844093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12.093037</td>\n",
       "      <td>240.966131</td>\n",
       "      <td>15.523084</td>\n",
       "      <td>0.770999</td>\n",
       "      <td>2.580544</td>\n",
       "      <td>64.289454</td>\n",
       "      <td>66.551321</td>\n",
       "      <td>27.215951</td>\n",
       "      <td>-15.112264</td>\n",
       "      <td>216.795404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10.095656</td>\n",
       "      <td>200.523411</td>\n",
       "      <td>14.160629</td>\n",
       "      <td>0.760132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.453132</td>\n",
       "      <td>28.295264</td>\n",
       "      <td>29.200587</td>\n",
       "      <td>-41.130285</td>\n",
       "      <td>183.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.067814</td>\n",
       "      <td>185.717082</td>\n",
       "      <td>13.627805</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.740454</td>\n",
       "      <td>12.548378</td>\n",
       "      <td>23.125349</td>\n",
       "      <td>-41.028033</td>\n",
       "      <td>125.632352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16.874026</td>\n",
       "      <td>512.042847</td>\n",
       "      <td>22.628364</td>\n",
       "      <td>0.678183</td>\n",
       "      <td>2.589715</td>\n",
       "      <td>62.573630</td>\n",
       "      <td>62.470021</td>\n",
       "      <td>36.396846</td>\n",
       "      <td>-40.739357</td>\n",
       "      <td>249.020577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.481181</td>\n",
       "      <td>203.082409</td>\n",
       "      <td>14.250699</td>\n",
       "      <td>0.648650</td>\n",
       "      <td>2.588658</td>\n",
       "      <td>17.844718</td>\n",
       "      <td>23.285337</td>\n",
       "      <td>32.442194</td>\n",
       "      <td>-46.438830</td>\n",
       "      <td>199.753918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17.258896</td>\n",
       "      <td>489.252073</td>\n",
       "      <td>22.119043</td>\n",
       "      <td>0.624955</td>\n",
       "      <td>2.555992</td>\n",
       "      <td>14.331179</td>\n",
       "      <td>17.071611</td>\n",
       "      <td>25.559476</td>\n",
       "      <td>-41.972611</td>\n",
       "      <td>208.194267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17.268755</td>\n",
       "      <td>469.572288</td>\n",
       "      <td>21.669617</td>\n",
       "      <td>0.366505</td>\n",
       "      <td>2.614312</td>\n",
       "      <td>54.461115</td>\n",
       "      <td>54.301755</td>\n",
       "      <td>39.984443</td>\n",
       "      <td>-33.120119</td>\n",
       "      <td>240.138531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file        mae         mse       rmse        r2  noise_mean  delay_median  \\\n",
       "6     6   7.935302  108.246762  10.404170  0.880453    2.571388     47.767941   \n",
       "7     7   7.935309  108.258770  10.404747  0.880439         NaN     45.772060   \n",
       "4     4  12.093037  240.966131  15.523084  0.770999    2.580544     64.289454   \n",
       "8     8  10.095656  200.523411  14.160629  0.760132         NaN     24.453132   \n",
       "0     0  10.067814  185.717082  13.627805  0.718328         NaN      9.740454   \n",
       "2     2  16.874026  512.042847  22.628364  0.678183    2.589715     62.573630   \n",
       "5     5  10.481181  203.082409  14.250699  0.648650    2.588658     17.844718   \n",
       "1     1  17.258896  489.252073  22.119043  0.624955    2.555992     14.331179   \n",
       "3     3  17.268755  469.572288  21.669617  0.366505    2.614312     54.461115   \n",
       "\n",
       "   delay_mean  delay_std  delay_min   delay_max  \n",
       "6   48.991473  24.054547 -34.903859  225.296308  \n",
       "7   43.362738  30.139726 -38.267560  170.844093  \n",
       "4   66.551321  27.215951 -15.112264  216.795404  \n",
       "8   28.295264  29.200587 -41.130285  183.495870  \n",
       "0   12.548378  23.125349 -41.028033  125.632352  \n",
       "2   62.470021  36.396846 -40.739357  249.020577  \n",
       "5   23.285337  32.442194 -46.438830  199.753918  \n",
       "1   17.071611  25.559476 -41.972611  208.194267  \n",
       "3   54.301755  39.984443 -33.120119  240.138531  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read metrics csv file and save on a Pandas DataFrame order by r2\n",
    "df_metrics = pd.read_csv('../data/metrics.csv')\n",
    "df_metrics = df_metrics.sort_values(by=['r2'], ascending=False)\n",
    "df_metrics\n",
    "# df_metrics[['file', 'r2', 'noise_mean', 'delay_median', 'delay_mean']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
